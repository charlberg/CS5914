{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88df2e9d-916d-4da3-968d-d4dabcc92aa6",
   "metadata": {},
   "source": [
    "# REGEX Pattern Match Progam\n",
    "### Assignment 1, Programming in Python\n",
    "**Note:** *Two literary works, 'Pride and Prejudice' and 'A Tale of Tiw Cities', were provided to test the program. For the program to operate as correctly, it is understood the script and texts are stored in the same directory.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc7b43-cf87-43d7-83fd-367d142e6ce4",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ccc81-1038-4f62-a221-6e627eedcccf",
   "metadata": {},
   "source": [
    "## 1. DEVELOPMENT PRINCIPLES\n",
    "### 1.1 Conceptual Framework\n",
    "The program prints and returns results for short strings and patterns from exact and multi-pattern searches of literary texts which are short enough for linear time solutions to work efficiently. We expect to achieve an average time requirement for simple string search of O(n) i.e. linear iterates through the string, but this can theoretically be improved using pattern preprocessing such as a sliding window approach with optimization or heuristics e.g. Rabin-Karp, Boyer Moore algorithms to achieve O(n) and O(n/m) respectively, or text preprocessing with a Suffix tree approach to achieve a performance of O(m). <br>\n",
    "*For more details, see Appendix 1: String Search & Pattern Matching Notes & References*<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5336de-b958-4ce2-bbe8-9851deb07209",
   "metadata": {},
   "source": [
    "### 1.2 REGEX Approach\n",
    "REGEX uses sophisticated alogrithms for pattern matching including Finite State Automata and Thompson NFA.  During testing on the texts specified for this assignment, the REGEX solution outperformed several popular sliding window and trie matching algorithms.  However, in real world applications using very large texts or datasets such as DNA sequence matching, Intrusion Detection Systems or datasets compiling data mining, the average performance of search algorithms will typically outperform REGEX and naive/brute force approaches.  <br>\n",
    "*For a comparison of performace, see Appendix 2: REGEX solution v. Knuth-Morris-Pratt, Wu-Manber, etc)* <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e78c81f-6588-47da-92a3-59faa338967a",
   "metadata": {},
   "source": [
    "### 1.3 Time and Space efficiency\n",
    "The regex solution performs a linear search with a time of O(n) (best case) and O(n*m) (worst case), We will also look at a more efficient algorithm for large texts and long patterns, the Boyes Moore Algorithm, which has preprocessing Time complexity of O(m) for the bad character table and good suffix table and best case/worst case search time complexity of O(m) and O(n+m). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77f493-651a-4770-8b5a-7028e0cd87bd",
   "metadata": {},
   "source": [
    "|Algorithm |Preprocessing time |Complicity matching time|\n",
    "|:---|:---:|---:|\n",
    "|Naïve string search algorithm| 0 (no preprocessing) |O((n-m+1) m)| \n",
    "|Trie-matching |0 (no preprocessing) |O (m + · n)|\n",
    "|Rabin-Karp string search algorithm |θ(m) |O((n-m+1) m)| \n",
    "|Finite automata |O(m |Σ|)| θ(n)|\n",
    "|Knuth-Morris Pratt algorithm |θ(m) |θ(n)| \n",
    "|Boyer-Moore string search algorithm |O(m)| average O(n/m)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef06296-b3c8-4602-a81a-b87446434c17",
   "metadata": {},
   "source": [
    "### 1.3 References\n",
    "* *A Fast string-Matching Algorithm*, R. S. Boyer, J. S. Moore (ACM, 1977)<br>\n",
    "* *Analysis of Multiple String Pattern Matching Algorithms*, A. I. Jony, (IJASCIT, 2014)<br>\n",
    "* *Multiple Skip Multiple Pattern Matching Algorithm (MSMPMA)*, Z. Qadi, M.J. Aqel, I. El Emary (IJSC, 2007)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d03cc-2d5e-4e10-a0c4-bf097cb6d3d2",
   "metadata": {},
   "source": [
    "Additional references are listed in Appendix 1<br>\n",
    "An invaluable resource is J.S. Moore's personal website, which has excellent examples of how different fast matching algorithms work:<br>\n",
    "https://www.cs.utexas.edu/~moore/best-ideas/string-searching/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f5449-5ca2-4009-9ea0-b4e7b60f5aea",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0222921-ff40-4c5c-a35d-c3efcde7bb54",
   "metadata": {},
   "source": [
    "# 2. Iterative Development of Program\n",
    "The program is iteratively developed as follows:<br>\n",
    "*  Formulation of function for Text Loading & String Count \n",
    "*  Formulation of function for pattern matching with counter\n",
    "*  Error handling with exceptions\n",
    "*  Combination of functions and driver in simple program with docstrings, annotation & dynamic formatting\n",
    "*  Testing of program with string and list inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fddcdb-ee60-4076-a6b5-ba5bbb40db6d",
   "metadata": {},
   "source": [
    "## 2.1 LOAD TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40894318-5a88-4296-a032-2c50aeb4bcfa",
   "metadata": {},
   "source": [
    "For the assignment, a word is defined as a continuous sequence of characters from the ranges A–Z, a–z, 0–9, and the underscore (`_`) character which corresponds to the regular expression '\\w', or '\\w+' for counting all instances of the substring. All other characters are ignored for counting words in the selected text e.g \"they're\" counts as two separate words \"they\" and \"re\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58701fd-ebb1-4d9f-bfec-daced54c9ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text contains are 138206 words in a-tale-of-two-cities.txt\n"
     ]
    }
   ],
   "source": [
    "import re # only library permitted for exercise\n",
    "\n",
    "# Open, read & close selected text using 'with'\n",
    "file_path = 'a-tale-of-two-cities.txt' \n",
    "with open(file_path, \"r\", encoding = \"utf-8\") as f:  # NB: utf-8 encoding neccessary \n",
    "    text = f.read()\n",
    "\n",
    "# Use re.findall() to determine word count for the text\n",
    "text_length = len(re.findall('\\\\w+', text))  \n",
    "print(f\"The text contains are {text_length} words in {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e8902-79b7-4ecb-a0a0-e43d5c69a450",
   "metadata": {},
   "source": [
    "## 2.2 PATTERN MATCHING WITH REGEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18d175-3f20-4bcb-9943-33d62436fa22",
   "metadata": {},
   "source": [
    "### *Single String Pattern & Frequency*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d25749f-0443-4792-9351-9c4e832abfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'France' appears 59 times\n"
     ]
    }
   ],
   "source": [
    "# Use RE to define pattern \n",
    "word = \"France\"  # Random word input\n",
    "pattern = '\\\\b' + word + '\\\\b' \n",
    "\n",
    "# Match all instances of the pattern and return count in string\n",
    "frequency = len(re.findall(pattern, text, re.IGNORECASE))  #  search should not be case-sensitive\n",
    "print(f\"The word '{word}' appears {frequency} times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c51bee-3605-4406-be51-f217166e2202",
   "metadata": {},
   "source": [
    "### *List Pattern & Frequency*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bddab4-d9a8-4d24-899c-0a1ef6d5bfc1",
   "metadata": {},
   "source": [
    "Terms are not limited to single words, but can also be a list of words/terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50db3b2c-869a-416a-ac81-1a3e0f929ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man occurance = 300\n",
      "woman occurance = 74\n"
     ]
    }
   ],
   "source": [
    "# Create a loop for pattern list\n",
    "substring_list = ['man', 'woman']\n",
    "for word in substring_list:\n",
    "    word = word.strip()\n",
    "    pattern = '\\\\b' + word + '\\\\b'\n",
    "    frequency = len(re.findall(pattern, text, re.IGNORECASE)) \n",
    "    print(f\"{word} occurance = {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb08aa1-ce68-4b58-bec9-a6733fbb70da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man occurance = 300\n",
      "woman occurance = 74\n",
      "Total patterns found: 374\n"
     ]
    }
   ],
   "source": [
    "# Include a counter for list results\n",
    "substring_list = ['man', 'woman']\n",
    "counter = 0 \n",
    "for word in substring_list:\n",
    "    word = word.strip()\n",
    "    pattern = '\\\\b' + word + '\\\\b'\n",
    "    frequency = len(re.findall(pattern, text, re.IGNORECASE))  # Repeat frquency call for this part of function \n",
    "    counter += frequency # Count increments of frequency\n",
    "    print(f\"{word} occurance = {frequency}\")\n",
    "print(f\"Total patterns found: {counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86a6f2-037e-4899-b72d-a49b24e8bea1",
   "metadata": {},
   "source": [
    "## 2.3 FUNCTIONS & ERROR HANDLING\n",
    "To simplify the program's development, debugging errors and maintenance, we create two individual functions. Any detected lexical, syntactic and semantic errors are caught with a simple catch-all 'Exceptions as e:' formulation and printed (not raised) using f-string formatting with distinct error message to report to users to unambiguously identify the source of an error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca9ac7-faf7-46ea-93dc-5d65cae864d1",
   "metadata": {},
   "source": [
    "### *File Opener*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14428b0-8622-46b8-83c1-ea52f1714048",
   "metadata": {},
   "source": [
    "The file opener uses a 'try..except' formulation to facilitate error handling. Rather than raising the error and stopping the program, an error report indicates the source of the problem to the user. For simplicity, the catchall \"Exception as e:\" is used with a message clearly indicating to users of the final program that the error was raised in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565af42f-0145-4081-a5c4-71fbfd400068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_opener(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
    "            text = f.read()  \n",
    "            word_count = len(re.findall('\\\\w+', text))            \n",
    "            print(f\"There are {word_count} words in the text '{file_path}'\")\n",
    "            return text\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Please check file_path, an error occured: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e819f5-3343-44de-9795-8497df73d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check file_path, an error occured: [Errno 2] No such file or directory: 'wrong_file_name'\n"
     ]
    }
   ],
   "source": [
    "# Check error reporting is working\n",
    "file_opener(\"wrong_file_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474d11c-3e59-46b2-be64-301a44c35bae",
   "metadata": {},
   "source": [
    "### *2.3.2 Word Counter*\n",
    "The word counter uses a boolean conditional ('if'.. 'else') to determine if the search terms are handled as a single word or list.  The conditional is wrapped in a 'try/except' structure to facilitate error handling. Outputs are not formatted at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ea284d-5439-49fa-94fd-120cb3aeab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search function\n",
    "def word_count_with_regex(file_path, search_terms):\n",
    "\n",
    "    # Open file with opener function\n",
    "    text = file_opener(file_path)\n",
    "    \n",
    "    # Search for frequency of substring/pattern\n",
    "    try:                \n",
    "        # boolean handles input as word or list of words\n",
    "        if isinstance(search_terms, str): \n",
    "            pattern = '\\\\b' + search_terms + '\\\\b'\n",
    "            frequency = len(re.findall(pattern, text, re.IGNORECASE))\n",
    "            print(f\"The word '{search_terms}' appears {frequency} times.\\n\")\n",
    "        \n",
    "        else:\n",
    "            # Input is a list for pattern match, not a word for exact substring match \n",
    "            print(f\"The {len(search_terms)} search terms appear appear in this text as follows: \\n\")          \n",
    "\n",
    "            # Strip words from substring list\n",
    "            counter = 0 \n",
    "            for word in search_terms:\n",
    "                word = word.strip()\n",
    "                pattern = '\\\\b' + word + '\\\\b'\n",
    "                frequency = len(re.findall(pattern, text, re.IGNORECASE))  # frquency call for this part of function only \n",
    "                counter += frequency \n",
    "                print(f\"{word} occurance = {frequency}\")\n",
    "            print(f\"Total patterns found: {counter}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Please check search_terms. An error occured: {e}\")\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963cfb2c-b73c-4fb7-85a6-862604653e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138206 words in the text 'a-tale-of-two-cities.txt'\n",
      "The 3 search terms appear appear in this text as follows: \n",
      "\n",
      "man occurance = 300\n",
      "woman occurance = 74\n",
      "horse occurance = 24\n",
      "Total patterns found: 398\n"
     ]
    }
   ],
   "source": [
    "word_count_with_regex('a-tale-of-two-cities.txt', ['man', 'woman', 'horse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcdf7e3-2520-4079-8216-a7af8d4aae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138206 words in the text 'a-tale-of-two-cities.txt'\n",
      "Please check search_terms. An error occured: object of type 'int' has no len()\n"
     ]
    }
   ],
   "source": [
    "# Check error handling\n",
    "word_count_with_regex('a-tale-of-two-cities.txt', 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c942ae-63f8-4250-87d1-9adb9d011305",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18cfed4-25bd-473d-a9a3-f10690fa4e05",
   "metadata": {},
   "source": [
    "# 3. Combining Functions to create Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806819f2-8503-4588-b326-8f14d618aaea",
   "metadata": {},
   "source": [
    "The functions with regex appear to be working as intended so we can build the program with the desired formatting. The program combines the two functions with a driver and returns results in sentence or table format with a a dynamic layout using f-string formatting and docstrings to explain the function.  The file_opener function passes the selected text/string to the word_counter function for matching search instances of the sub-string/pattern.  In order to prevent NameError defaults, the driver provides default values for the text and term_search parameters. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f48c13-c981-49fd-9f03-6c5bf172d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 122900 words in the text 'pride-and-prejudice.txt'\n",
      "The 3 search terms appear appear in this text as follows: \n",
      "\n",
      "| -------- | -------- |\n",
      "|   Word   |  Count   |\n",
      "| -------- | -------- |\n",
      "| man      |      150 |\n",
      "| woman    |       61 |\n",
      "| horse    |        3 |\n",
      "| -------- | -------- |\n",
      "| Total    |      214 |\n",
      "| -------- | -------- |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NB. Code block can be run from terminal\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import re\n",
    "\n",
    "def file_opener(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    A context manager function that automatically opens/closes texts \n",
    "    Output: Returns selected text, reports file handling errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
    "            content = f.read()  \n",
    "            word_count = len(re.findall('\\\\w+', content))    # Regex 'words' defined as A–Z, a–z, 0–9, _\n",
    "            print(f\"There are {word_count} words in the text '{file_path}'\")\n",
    "            return content\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"A file_path error occured: {e}\")\n",
    "\n",
    "\n",
    "# Define search function\n",
    "def word_count_summary(file_path: str, search_terms: str) -> list[int]:\n",
    "    \"\"\"\n",
    "    Scans for frequency of substrings & patterns in str texts\n",
    "    Arguments: \n",
    "        Name and path of a file containing text\n",
    "        String input of substring/pattern\n",
    "    Returns:  \n",
    "        Exact match of substring/individual words (str)\n",
    "        Muliti-pattern match for list of words (in tabular format int[])\n",
    "    \"\"\"\n",
    "    # Open file with opener function\n",
    "    content = file_opener(file_path)\n",
    "    \n",
    "    # Search for frequency of terms/expressions\n",
    "    try:                \n",
    "        if isinstance(search_terms, str): # input is string, not list\n",
    "            pattern = '\\\\b' + search_terms + '\\\\b'\n",
    "            frequency = len(re.findall(pattern, content, re.IGNORECASE))\n",
    "            print(f\"The word '{search_terms}' appears {frequency} times.\\n\")\n",
    "            return frequency\n",
    "        \n",
    "        else:\n",
    "            print(f\"The {len(search_terms)} search terms appear appear in this text as follows: \\n\")  # Input is a list, not string\n",
    "        \n",
    "            # Dynamic formatting for table\n",
    "            longest_term = max((term.strip() for term in search_terms), key=len)  # determines minimum lenght of columns\n",
    "            column_width = len(longest_term) if len(longest_term) > 8 else 8  # sets minimum width of columns\n",
    "            line_break = f\"| {'-' * column_width} | {'-' * column_width} |\"  # Formatting for header/end breaks\n",
    "\n",
    "            # Print header\n",
    "            header = \"| {0:^{1}} | {2:^{1}} |\".format('Word', column_width, 'Count') # header center-aligned\n",
    "            print(f\"{line_break}\\n{header}\\n{line_break}\")\n",
    "\n",
    "            # Strip terms for multi-term search\n",
    "            word_counter = 0 \n",
    "            for word in search_terms:\n",
    "                word = word.strip()\n",
    "                pattern = '\\\\b' + word + '\\\\b'\n",
    "                frequency = len(re.findall(pattern, content, re.IGNORECASE))\n",
    "                word_counter += frequency\n",
    "                print(f\"| {word:<{column_width}} | {frequency:>{column_width}} |\")  # Output aligned left/right by column\n",
    "    \n",
    "            #  Aggregate search counts of all strings \n",
    "            sum_total = f\"| {'Total':<{column_width}} | {word_counter:>{column_width}} |\"\n",
    "            print(f\"{line_break}\\n{sum_total}\\n{line_break}\\n\")\n",
    "            return word_counter\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"A counter error occured: {e}\")\n",
    "        \n",
    "    return\n",
    "\n",
    "# Set driver code default values to  \n",
    "# prevent TypeError/NameErrors when run as program \n",
    "if __name__ == '__main__':\n",
    "    file_path  = 'pride-and-prejudice.txt'\n",
    "    search_terms  = ['man', 'woman', 'horse']\n",
    "    word_count_summary(file_path, search_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769204de-ac27-457a-bb79-ce7e361392b6",
   "metadata": {},
   "source": [
    "### *Testing the Program*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5a51ec5-b0a8-4991-b34f-1ddbdf003f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function word_count_summary in module __main__:\n",
      "\n",
      "word_count_summary(file_path: str, search_terms: str) -> list[int]\n",
      "    Scans for frequency of substrings & patterns in str texts\n",
      "    Arguments:\n",
      "        Name and path of a file containing text\n",
      "        String input of substring/pattern\n",
      "    Returns:\n",
      "        Exact match of substring/individual words (str)\n",
      "        Muliti-pattern match for list of words (in tabular format int[])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(word_count_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d64f539-ed38-4621-89e9-ab190ce246bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 122900 words in the text 'pride-and-prejudice.txt'\n",
      "The word 'the' appears 4333 times.\n",
      "\n",
      "There are 122900 words in the text 'pride-and-prejudice.txt'\n",
      "The 5 search terms appear appear in this text as follows: \n",
      "\n",
      "| --------- | --------- |\n",
      "|   Word    |   Count   |\n",
      "| --------- | --------- |\n",
      "| Jane      |       292 |\n",
      "| Elizabeth |       634 |\n",
      "| Mary      |        39 |\n",
      "| Kitty     |        71 |\n",
      "| Lydia     |       171 |\n",
      "| --------- | --------- |\n",
      "| Total     |      1207 |\n",
      "| --------- | --------- |\n",
      "\n",
      "There are 122900 words in the text 'pride-and-prejudice.txt'\n",
      "The 3 search terms appear appear in this text as follows: \n",
      "\n",
      "| -------- | -------- |\n",
      "|   Word   |  Count   |\n",
      "| -------- | -------- |\n",
      "| round    |       17 |\n",
      "| ability  |        0 |\n",
      "| enemy    |        1 |\n",
      "| -------- | -------- |\n",
      "| Total    |       18 |\n",
      "| -------- | -------- |\n",
      "\n",
      "There are 122900 words in the text 'pride-and-prejudice.txt'\n",
      "The 5 search terms appear appear in this text as follows: \n",
      "\n",
      "| ------------ | ------------ |\n",
      "|     Word     |    Count     |\n",
      "| ------------ | ------------ |\n",
      "| old man      |            0 |\n",
      "| strong woman |            0 |\n",
      "| love         |           92 |\n",
      "| marriage     |           66 |\n",
      "| happy        |           83 |\n",
      "| ------------ | ------------ |\n",
      "| Total        |          241 |\n",
      "| ------------ | ------------ |\n",
      "\n",
      "There are 138206 words in the text 'a-tale-of-two-cities.txt'\n",
      "The word 'pizza' appears 0 times.\n",
      "\n",
      "There are 138206 words in the text 'a-tale-of-two-cities.txt'\n",
      "The 2 search terms appear appear in this text as follows: \n",
      "\n",
      "| -------- | -------- |\n",
      "|   Word   |  Count   |\n",
      "| -------- | -------- |\n",
      "| London   |       28 |\n",
      "| Paris    |       63 |\n",
      "| -------- | -------- |\n",
      "| Total    |       91 |\n",
      "| -------- | -------- |\n",
      "\n",
      "There are 138206 words in the text 'a-tale-of-two-cities.txt'\n",
      "The 6 search terms appear appear in this text as follows: \n",
      "\n",
      "| ---------- | ---------- |\n",
      "|    Word    |   Count    |\n",
      "| ---------- | ---------- |\n",
      "| sacrifice  |          6 |\n",
      "| fear       |         26 |\n",
      "| death      |         67 |\n",
      "| guillotine |         26 |\n",
      "| victims    |          5 |\n",
      "| orphan     |          5 |\n",
      "| ---------- | ---------- |\n",
      "| Total      |        135 |\n",
      "| ---------- | ---------- |\n",
      "\n",
      "There are 138206 words in the text 'a-tale-of-two-cities.txt'\n",
      "The 3 search terms appear appear in this text as follows: \n",
      "\n",
      "| ------------ | ------------ |\n",
      "|     Word     |    Count     |\n",
      "| ------------ | ------------ |\n",
      "| innocent man |            2 |\n",
      "| God          |           30 |\n",
      "| the devil    |           12 |\n",
      "| ------------ | ------------ |\n",
      "| Total        |           44 |\n",
      "| ------------ | ------------ |\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the program with both texts and search for a string/list of strings\n",
    "\n",
    "# Love and 18th century happiness\n",
    "word_count_summary(\"pride-and-prejudice.txt\", \"the\")  # test words from Assignment notes\n",
    "word_count_summary(\"pride-and-prejudice.txt\", [\"Jane\", \"Elizabeth\", \"Mary\", \"Kitty\", \"Lydia\"])  # test a list of words  \n",
    "word_count_summary(\"pride-and-prejudice.txt\", [\"round\", \"ability\", \"enemy\"])   # test words from Assignment Appendix\n",
    "word_count_summary(\"pride-and-prejudice.txt\", [\"old man\", \"strong woman\", \"love\", \"marriage\", \"happy\"])  \n",
    "\n",
    "# War, evil and self-sacrifice\n",
    "word_count_summary(\"a-tale-of-two-cities.txt\", \"pizza\")\n",
    "word_count_summary(\"a-tale-of-two-cities.txt\", [\"London\", \"Paris\"])\n",
    "word_count_summary(\"a-tale-of-two-cities.txt\", [\"sacrifice\", \"fear\", \"death\", \"guillotine\", \"victims\", \"orphan\"])  \n",
    "word_count_summary(\"a-tale-of-two-cities.txt\", [\"innocent man\", \"God\", \"the devil\"])   # test list of strings and patterns            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80aa98-8bd4-4cc1-9bf1-f3d3ac54d1b3",
   "metadata": {},
   "source": [
    "# 4. Algorithm Optimization with Heuristics: Boyer Moore Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887c952-567f-478c-8b00-adcd1e065387",
   "metadata": {},
   "source": [
    "*\"Our algorithm has the peculiar property that, roughly speaking, the longer the pattern is, the faster the algorithm goes. Furthermore, the algorithm is ``sublinear'' in the sense that it generally looks at fewer characters than it passes.\"* J.S. Moore "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c9da6-cf52-4282-8190-a9bcf4110d45",
   "metadata": {},
   "source": [
    "As indicated, there are several sliding window alogorithms for improving the pattern matching performance on large datasets using pattern preprocessing algorithms or preprocessing of the text for substring search using suffixes.  A workbook examing the relative performance of representative algorithms can be found in Appendix 2. Where certain algorithms performed well for exact substring/pattern matching, their performance for multiple pattern matching was inferior to regular expressions and multi-pattern algorithms i.e. exact match alogorithms are obliged to loop through the search terms.  For the literary texts used in this exercies, the window shifting KMP and Boyer Moore algorithms outperformed the regex pattern search, while the exact search and trie algorithms were slower. <br>\n",
    "<br>\n",
    "It should be noted that this notebook does not pretend to offer an empirical analysis of the solution against algorithms for exact and multi-pattern searchs, but to put the REGEX solution in context by looking at one of the most popular window sliding algorithms for multiple pattern search, the Boyer Moore algoritm, which was the best performing algorithm on the exercise texts.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9f8597-06a2-488e-820b-e2d694d261e6",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "Proposed in 1977, the Boyer-Moore algorithm is a string matching algorithm that achieves high efficiency by beginning from the last character of the pattern and skipping sections of the text during the search phase. It leverages two heuristics: the bad character rule and the good suffix rule, which determine how far the pattern can be shifted when a mismatch occurs. These rules significantly reduce the number of comparisons, especially in practical scenarios where the pattern is long or the alphabet is large. The algorithm’s worst-case time complexity is O(n ⋅ m) but it performs close to O(n / m) on average for random text and patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e1ac4-71db-4aaa-b0d4-25097e814b5e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d536e87d-9a3b-4e2d-9cbb-b3bd4c5b3c95",
   "metadata": {},
   "source": [
    "**DISCLOSURE**<br>\n",
    "The code for the Boyer Moore model is not work that has been independently developed, it is derivative work that has been synthesized of several works, most importantly the following papers:<br>\n",
    "* **A Fast string-Matching Algorithm**, R. S. Boyer, J. S. Moore (ACM, 1977)<br>\n",
    "* **Analysis of Multiple String Pattern Matching Algorithms**, A. I. Jony, (IJASCIT, 2014)<br>\n",
    "* **Multiple Skip Multiple Pattern Matching Algorithm (MSMPMA)**, Z. Qadi, M.J. Aqel, I. El Emary (IJSC, 2007)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40950449-7dfc-4ed5-b852-b4be63c9e509",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f1dd21-8d53-42a3-a57b-a08091cd95a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 138206 words in the text 'a-tale-of-two-cities.txt'\n",
      "The 3 search terms appear appear in this text as follows: \n",
      "\n",
      "| -------- | -------- |\n",
      "|   Word   |  Count   |\n",
      "| -------- | -------- |\n",
      "| birds    |       10 |\n",
      "| women    |       61 |\n",
      "| horses   |       40 |\n",
      "| -------- | -------- |\n",
      "| Total    |      111 |\n",
      "| -------- | -------- |\n",
      "\n",
      "REGEX total time: 0.0806 seconds\n"
     ]
    }
   ],
   "source": [
    "# Additional libraries are used to compare the solutions\n",
    "import time  # Import the time library\n",
    "from collections import Counter\n",
    "\n",
    "def regex_counter(content, pattern):\n",
    "    re_total_time = 0\n",
    "    start_time = time.time()\n",
    "    word_count_summary(content, pattern)\n",
    "    end_time = time.time()\n",
    "    re_total_time = (end_time - start_time)\n",
    "    print(f\"REGEX total time: {re_total_time:.4f} seconds\")\n",
    "    \n",
    "regex_counter(\"a-tale-of-two-cities.txt\", [\"birds\", \"women\", \"horses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb2bdbb5-fc92-44c0-86c8-1ca6821ddf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 135660 words in the text: a-tale-of-two-cities.txt\n",
      "birds : 10 matches\n",
      "women : 61 matches\n",
      "horses : 40 matches\n",
      "\n",
      "Boyer-Moore total time: 0.1225 seconds\n"
     ]
    }
   ],
   "source": [
    "# Disclosure & Acknowledgment:\n",
    "# This version of the Boyer-Moore algorithm is\n",
    "# adapted from an interpretation found at GeeksforGeeks.com\n",
    "# https://www.geeksforgeeks.org/boyer-moore-algorithm-for-pattern-searching/\n",
    "# and a\n",
    "# https://github.com/je-suis-tm/search-and-sort/blob/master/boyer%20moore%20search.py\n",
    "\n",
    "def boyer_moore_search(content, pattern):\n",
    "  n = len(content)\n",
    "  m = len(pattern)\n",
    "  if m == 0 or m > n:\n",
    "      return []\n",
    "\n",
    "  bad_char = dict()\n",
    "  for i in range(m):\n",
    "      bad_char[ord(pattern[i])] = i\n",
    "\n",
    "  matches = []\n",
    "  shift = 0\n",
    "\n",
    "  # Slide the pattern over the content\n",
    "  while shift <= n - m:\n",
    "      j = m - 1\n",
    "\n",
    "      # Match pattern from the end\n",
    "      while j >= 0 and content[shift + j] == pattern[j]:\n",
    "          j -= 1\n",
    "\n",
    "      if j < 0:\n",
    "          # Pattern found at this shift\n",
    "          matches.append(shift)\n",
    "          # Move the pattern to the next possible position\n",
    "          shift += (m if (shift + m) < n else 1)  # Move by the full length or 1 if at the end of the text\n",
    "      else:\n",
    "          # Use the bad character heuristic to shift window\n",
    "          bad_char_shift = bad_char.get(ord(content[shift + j]), -1)  # Handle potential out-of-bounds access with dictionary\n",
    "          shift += max(1, j - bad_char_shift)\n",
    "\n",
    "  return matches\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_name = \"a-tale-of-two-cities.txt\"\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    patterns = [\"birds\", \"women\", \"horses\"]\n",
    "\n",
    "    total_words = count_words(text)\n",
    "    print(f\"There are {total_words} words in the text: {file_name}\")\n",
    "\n",
    "    total_matches = Counter()\n",
    "    bm_total_time = 0\n",
    "\n",
    "    for pattern in patterns:\n",
    "        start_time = time.time()\n",
    "        matches = boyer_moore_search(text, pattern)\n",
    "        end_time = time.time()\n",
    "\n",
    "        bm_total_time += (end_time - start_time)\n",
    "        total_matches[pattern] += len(matches)\n",
    "        \n",
    "        print(f\"{pattern} : {len(matches)} matches\")\n",
    "\n",
    "    print(f\"\\nBoyer-Moore total time: {bm_total_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1953418-b1b4-4884-b1e4-09ca8418e81d",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "The time performance of the Boyer-Moore algorithm at 0.127 seconds is significantly slower than REGEX at 0.0831\n",
    "seconds, though the the two solutions different number of 'words' detected in the text and different results for the search_terms. The performance of other algorithms can be found in the Jupyter notebook in Appendix 2.<br>\n",
    "It should be noted that the test is for illustration purposes only and not by any means an empirical demonstration of the efficiency of REGEX compared to sophisticated algorithms which would undoubtedly perform better on longer patterns and larger string inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f516eb-b3bc-43e5-953c-7f4496295a65",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a374618-6185-4ecd-93a6-07b6e7071879",
   "metadata": {},
   "source": [
    "### *Code References by Academic Module*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08440bf0-2f1a-421b-9485-96acf97e0df6",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293353f8-23ce-4d6f-9428-14eaaf9f58c3",
   "metadata": {},
   "source": [
    "**File Path (Lecture 14)**<br>\n",
    "The file path code is based on instruction received in Lecture 14, Files. While it is good practice to close the file to prevent the corruption of the file and avoid OS limitations using, a context manager allows Python to optimize the use of resources.<br>\n",
    "<br>\n",
    "**REGEX patterns & Word Count (Lecture 16)**<br>\n",
    "The REGEX search patterns are based on instruction received in Lecture 16, Regular Expression.  We search for (A–Z, a–z, 0–9, _ ) using the '\\\\w+' formulation. The selected text is searched for the search term using the pattern formulation of search term between word boundaries ('\\\\b'). <br> Please note that a more accurate count of words which excludes approx 100  numeric expressions can be obtained by using the code: <br>\n",
    "    _# word_pattern = '\\\\b[^\\d\\W_]+\\\\b'_ <br>\n",
    "    _# non_numeric_words = re.findall(word_pattern, text)_ <br>\n",
    "    _# numeric_count = word_count - len(non_numeric_count)_ <br>\n",
    "    _# print(f\"There are {word_count} strings in this text, including\", len(non_numeric_words), f\"words and {numeric_count} numerics\")_ <br>\n",
    "<br>\n",
    "**_Printf_ formatting (Lecture 11)**<br>\n",
    "The _printf_ formatting is based on instruction received in Lecture 11, String Manipulation. <br> \n",
    "Using a list comprehension, the program iterates through the words to obtain the maximum lenght of an unbundled list of terms to be included in the table of results. The minimum lenght of the table's equal-sized oolumns is set at 8 characters (dictated by the title words) with alignment of words in the title rows to the center using (^:{}), while the left ('Word') column is aligned to the left using (<:{}) and the right ('Count') column is aligned to the right using (>:{})<br>\n",
    "<br>\n",
    "**Input string & list of strings (Lecture 6)**<br>\n",
    "Per instruction in Lecture 6, Conditionals, we determine the processing of the search term using a boolean and _'if-else'_ conditional where the if statement processes the search terms either as a string or list. <br> \n",
    "*  Where the boolean is True, the search term is determined to be a single string and the frequency of the search term is returned within a string (a simple sentence).\n",
    "*  Where the boolean is False, the search terms is determined not to be a string but to be a list, and the frequecies are unpacked and iterated through a loop and recorded in a table formatted using printf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c72d96-74e7-41d7-b2db-0f1c1b028dd4",
   "metadata": {},
   "source": [
    "**Errors handling (Topic 2, Lecture 5)**<br>\n",
    "Per instruction in Topic 2: Lecture 5 'Structure: Errors and exception handling', we use the 'try-except' formulation for handling errors.  The errors are not returns, but error reports are printed ensuring that the source of the problem can easily be identified. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9160f-a675-4a07-aabb-a3e3a2fcf1f8",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed18c12-ea16-478f-b53d-c4a8e654f57c",
   "metadata": {},
   "source": [
    "### Appendices\n",
    "**Appendix 1:** *Overview of String Search & Search Pattern Matching Algorithms*<br>\n",
    "**Appendix 2:** *Jupyter Notebook: Comparison of Regex v. Popular Pattern Matching Algorithms*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22f432-0405-47db-a3b2-14125dd816be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
